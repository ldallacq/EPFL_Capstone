{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELON MUSK DATASET CREATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Twitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import csv\n",
    "maxTweets = 20000\n",
    "\n",
    "csvFile = open('Elon.csv', 'a', newline='', encoding='utf8')\n",
    "\n",
    "csvWriter = csv.writer(csvFile)\n",
    "csvWriter.writerow(['id','date','tweet',])\n",
    "\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:@elonmusk until:2020-11-01-filter:replies').get_items()):\n",
    "    if i > maxTweets :\n",
    "        break\n",
    "    csvWriter.writerow([tweet.id, tweet.date, tweet.content])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11287, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon = pd.read_csv('Elon.csv')\n",
    "elon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "elon = elon.drop_duplicates(subset = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11287, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elon.date = pd.to_datetime(elon.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2010       1\n",
       "2011      42\n",
       "2012     272\n",
       "2013     422\n",
       "2014     188\n",
       "2015     328\n",
       "2016     753\n",
       "2017    1160\n",
       "2018    2289\n",
       "2019    2930\n",
       "2020    2902\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon.groupby([elon['date'].dt.year])['id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likes and Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_to_scrape = elon['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = len(links_to_scrape)\n",
    "chunks = (total_count - 1) // 50 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = \n",
    "consumer_secret = \n",
    "access_token = \n",
    "access_token_secret = \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tw(links_to_scrape):\n",
    "    \n",
    "    list_of_tw_status = api.statuses_lookup(links_to_scrape, tweet_mode= \"extended\")\n",
    "    \n",
    "    empty_data = pd.DataFrame()\n",
    "    \n",
    "    for status in list_of_tw_status:\n",
    "            tweet_elem = {\"tweet_id\": str(status.id),\n",
    "                          \"tweet\":status.full_text,\n",
    "                          'likes': status.favorite_count, \n",
    "                          'retweets': status.retweet_count,\n",
    "                          \"date\":status.created_at}\n",
    "            empty_data = empty_data.append(tweet_elem, ignore_index = True)\n",
    "            \n",
    "    empty_data.to_csv(\"elon_with_likes.csv\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(chunks):\n",
    "        batch = links_to_scrape[i*50:(i+1)*50]\n",
    "        result = fetch_tw(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "elon_likes = pd.read_csv(\"elon_with_likes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "elon_likes = elon_likes.drop_duplicates(subset = 'tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11288, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon_likes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
