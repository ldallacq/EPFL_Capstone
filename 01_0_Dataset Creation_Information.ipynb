{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset I had to gather a good corpus of data for each persona. I tried to find online some good exmaples available either on GitHub or Kaggle and, to my surprise, I have found some data. Ultimately, when not finding any type of data, I decided to scrape Twitter. \n",
    "\n",
    "\n",
    "Below you can understand better where the data is coming from, depending on the Persona and in the next paragraph you will understand how I scraped Twitter for additional information I could not easily download online. \n",
    "\n",
    "**WARNING** \n",
    "I am sending the files I have scraped. In case you want to re-run the individual datasets creation please make sure to either delete the files or rename the files within the code. \n",
    "\n",
    "\n",
    "### Trump \n",
    "\n",
    "I have downloaded tweets from Trump from the online **Twitter Trump Archive**. I have downloaded the full history of the tweets of the tycoon, which consists of approximately **55K unique tweets** from 2009 to 2020 (unique Urls).  \n",
    "\n",
    "* Twitter page: https://twitter.com/JoeBiden\n",
    "* Handle: @realDonaldTrump\n",
    "* Source: https://www.thetrumparchive.com/?dates=%5B%222020-01-01%22%2C%222020-11-01%22%5D\n",
    "\n",
    "In this dataset I have these fields: \n",
    "\n",
    "* id (basically the URL of the post)\n",
    "* text (the tweet)\n",
    "* isRetweeted \n",
    "* isDeleted\n",
    "* device (whether Android, IOS or TweetDeck)\n",
    "* favorites (e.g. the likes to the post)\n",
    "* retweets\n",
    "* date \n",
    "\n",
    "### Biden\n",
    "\n",
    "Joe Biden tweets are coming from **Kaggle** (link below).\n",
    "\n",
    "* Twitter page: https://twitter.com/JoeBiden\n",
    "* Handle: @JoeBiden\n",
    "* Source: https://www.kaggle.com/rohanrao/joe-biden-tweets\n",
    "\n",
    "There are 6000 unique tweets in this dataset (unique URL) and they range from 2007 to 2020. Despite the project is very recent on Kaggle (October 31st), I decided to still scrape the data myself from Twitter to understand if there was some mismatch in terms of figures, and there isn't. Indeed on the JoeBiden twitter you can clearly see that the politician has approximately **6K unique tweets** in total. \n",
    "\n",
    "In this dataset I have these fields: \n",
    "* id (URL)\n",
    "* timestamp (date)\n",
    "* url \n",
    "* tweet\n",
    "* replies\n",
    "* retweets\n",
    "* quotes\n",
    "* likes \n",
    "\n",
    "\n",
    "### Kim Kardashian\n",
    "\n",
    "For Kim I could not find a reliable dataset easily online, hence I decided to **scrape the dataset**. I will explain how I did this in the next paragraph. I have approximately **29K unique tweets** (unique URL) from the American influencer from 2009 to nowadays. \n",
    "\n",
    "* Twitter page: https://twitter.com/KimKardashian\n",
    "* Handle: @KimKardashian\n",
    "* Source: Scraped dataset with a combination of Snscrape + Tweepy\n",
    "\n",
    "For Kim, I have this final dataset: \n",
    "\n",
    "* date\t\n",
    "* likes\t\n",
    "* retweets\t\n",
    "* tweet\t\n",
    "* tweet_id (the URL)\n",
    "\n",
    "\n",
    "### Pope Francis\n",
    "\n",
    "Similarly to Kim Kardashian, for Pope Francis I had to **scrape the dataset** from Twitter. For the Pontifex, I have the smallest base size out of the 4 personas: **2.8K unique tweets**, from 2013 to nowadays. \n",
    "\n",
    "* Twitter page: https://twitter.com/Pontifex\n",
    "* Handle: @Pontifex\n",
    "* Source: Scraped dataset with a combination of Snscrape + Tweepy\n",
    "\n",
    "Similarly to Kim, in this dataset I have: \n",
    "\n",
    "* id (the URL)\n",
    "* tweet\n",
    "* date\n",
    "* likes\n",
    "* retweets \n",
    "\n",
    "\n",
    "### Elon Musk\n",
    "\n",
    "I followed the same procedure as for Kim Kardashian and the Pontifex and I **scrape the dataset** from Twitter for Elon Musk. I have in total: **11.3K unique tweets**, from 2012 to nowadays. At this point I am feeling confident to keep the Pope in the circle. \n",
    "\n",
    "* Twitter page: https://twitter.com/elonmusk\n",
    "* Handle: @elonmusk\n",
    "* Source: Scraped dataset with a combination of Snscrape + Tweepy\n",
    "\n",
    "Similarly to Kim and the Pope, in this dataset I have: \n",
    "\n",
    "* id (the URL)\n",
    "* tweet\n",
    "* date\n",
    "* likes\n",
    "* retweets  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWITTER SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, for Elon, the Pope and Kim Kardashian I did not have any preliminary dataset to work on, hence I had to scrape from scratch all the Tweets. Here I am detailing exactly how I obtained the datasets. \n",
    "\n",
    "### 1. **Request for Twitter Developer account** \n",
    "\n",
    "I requested the Twitter Developer account in order to obtain the keys to scrape Twitter through their APIs. It was a simple task and it really did not take too much time to get the green light from Twitter (1 working day). \n",
    "In order to scrape data, Twitter gave me unique: \n",
    "\n",
    "* consumer_key \n",
    "* consumer_secret \n",
    "* access_token \n",
    "* access_token_secret \n",
    "\n",
    "To request Twitter Developer account follow this link: https://developer.twitter.com/en\n",
    "\n",
    "### 2. ** Use Snscrape** \n",
    "\n",
    "I have used Snscraper in order to get scrape the Tweets from the celebrities. I have not set a datetime limit to start scraping the tweets, yet I have just put the end date similar to all the personas (11.11.2020). Snscrape gives you the possibility to retrieve: \n",
    "\n",
    "* id (URL)\n",
    "* date\n",
    "* tweet\n",
    "\n",
    "It does not allow you to retrieve more information as for likes and retweets (not that I am aware), for that I needed to use Tweepy (which uses the keys from the Developer account in Twitter). See below.\n",
    "\n",
    "\n",
    "### 3. ** Use Tweepy**\n",
    "\n",
    "I have used Tweepy to retrieve the information of likes and retweets for each ID I obtained from the snscrape. \n",
    " \n",
    "* I have first put the Ids into a list which would serve Tweepy to search for information for those Ids (urls). \n",
    "* I have then requested Tweepy to download favorite_count (e.g. the likes) and the retweet_count (the retweets) for each id. \n",
    "* I have had to divide the request into batches because Twitter cannot handle big batches of data to the API at the same time. \n",
    "* I finally got the information I wanted. \n",
    "\n",
    "\n",
    "### **NOTE** \n",
    "\n",
    "I had to do quite an extensive search online in order to understand which library to use to scrape data. I have also downloaded **Octoparse** which is a software to help you scrape easily any page online (despite there is a price beyond the scraping if you want to dowload the datasets you scraped). \n",
    "\n",
    "I believe that there is a much simpler way to retrieve data than the ones I used, through **GetOldTweets3** which allows you to retrieve all the information (with  @mentions and hashtags in addition), all at once. However, it seems like there is a problem with the Twitter API that has changed one of the endpoints very recently (end of September 2020). As a consequence of GetOldTweets not working, I had to search for alternative ways to obtain the dataset and that's when I found suggestions to mix Snscrape and Tweepy from GitHub. \n",
    "\n",
    "Unfortunately this type of events are not rare as Social Media are continuously changing their policies (e.g. Instagram big API deprecation on Dec 13th 2019). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
